{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Assignment 2023</b><br>\n",
    "ANALYSIS OF SPECTROPHOTOMETRIC AND PHYSICAL PROPERTIES OF GALAXIES<br><br>\n",
    "EXTRAGALACTIC ASTRONOMY (AST4001)<br><br><br>\n",
    "\n",
    "Catarina Lobo - clobo@fc.up.pt\n",
    "<br>Jean Gomes - jean@astro.up.pt\n",
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SUBMISSION INSTRUCTIONS:</b>\n",
    "\n",
    "At the end of this assignment, you should submit, by email, to clobo@fc.up.pt and jean@astro.up.pt:\n",
    "\n",
    "<b>i)</b> a report (pdf version) with the answer to each question below. In each item you must provide a plot (if asked for) and a concise but complete argument (this means you must include a justification for the answer you provide) and, when applicable, the formula(s) (or codes) you used when computing a new quantity. Remember to indicate all steps to solve a given problem, code or when you derive a formula. \n",
    "\n",
    "- This assignement uses the repository https://github.com/neutrinomuon/AST4001-Extragalactic-Astronomy. You can clone the repository in the following manners:\n",
    "     \n",
    "1) Under <b>Linux/macOS-Unix based or Windows</b> you may use the Terminal (or also Powershell in Windows) and do:\n",
    "    \n",
    "<pre>git clone https://github.com/neutrinomuon/AST4001-Extragalactic-Astronomy</pre>\n",
    "    \n",
    "<b>P.S.:</b> Make sure you have git installed.If you are under Linux, MacOSX or Windows the easiest way to install <a href='https://python.spectralsynthesis.org/blog/publicacao/2190906/como-instalar-o-python-de-maneira-r-pida-e-f-cil-anaconda'>How to easily install Python in your machine?</a>\n",
    "    \n",
    "    \n",
    "2) Under <b>Windows</b> go to the following page https://git-scm.com/book/en/v2/Getting-Started-Installing-Git and install git.\n",
    "    \n",
    "3) In <b>ANY Operational System</b> you can also go directly to the link https://github.com/neutrinomuon/AST4001-Extragalactic-Astronomy and download the archives as the following images show.\n",
    "    \n",
    "<html>\n",
    "<center><img src=https://github.com/neutrinomuon/AST4001-Extragalactic-Astronomy/blob/master/figures/Download_Part1.png?raw=true\" width=\"65%\"></center>\n",
    "<center><img src=\"https://raw.githubusercontent.com/neutrinomuon/AST4001-Extragalactic-Astronomy/figure/Download_Part2.png\" width=\"65%\"></center>\n",
    "</html>  \n",
    "    \n",
    "- You will need to use Python (use only Python3, preference Python >= 3.8) to fulfill your assignment;\n",
    "\n",
    "- If you wish you may consider using this jupyter notebook by adding more <font color='red'>cells</font> below each question to answer them.\n",
    "\n",
    "Good luck in the preparation of the material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Star clusters, i.e. Simple Stellar Populations as the buiding blocks of galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>1)</strong> Assuming a Salpeter IMF with a slope of 1.35, according to Tinsley notation $\\phi(m) \\propto m^{-(\\alpha+1)}$. Assume that the minimum and maximum stellar masses are $m_{low}=0.1 M_\\odot$ and $m_{up}=100 M_\\odot$, respectively. Generate artificially a star cluster with $10^6$ stars and then plot the histogram of stars as a function of mass. \n",
    "\n",
    "Hint:\n",
    "\n",
    "I) First evaluate the proportionality constant $\\kappa$ in the Salpeter equation using the normalization condition. \n",
    "\n",
    "II) Assume that the probability density is given by $p(m) = \\kappa m^{-(\\alpha+1)}$, so \n",
    "\n",
    "\\begin{equation}\n",
    "N(m) = \\int_{m_{low}}^{m} m p(m) dm\n",
    "\\end{equation} \n",
    "\n",
    "is a number (or probability) between 0 and 1 for a given mass m. Compute the functional form of the equation above if $\\alpha = 1.35$. Inverting this equation, one has a mass $m$ for a given number (or probability) between 0 and 1, therefore this is usually called \"mass generator\", i.e. a function of a number between 0 and 1:\n",
    "\n",
    "\\begin{equation}\n",
    "m(N) = \\textrm{function}(N)\n",
    "\\end{equation}\n",
    "\n",
    "III) After having m(N), use a pseudo random number generator between 0 and 1 to build your star cluster. For that you can use the Class Random from python, and generate a uniform distribution from [0,1]. Use a specific initial seed for the result to be reproducible, i.e. random.seed(a=None, version=2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>2)</strong> This problem is to evaluate the time evolution of colors due to the stellar populations. You will need to use the Simple Stellar Populations from Bruzual & Charlot, 2003, MNRAS, 344, 1000B (https://ui.adsabs.harvard.edu/abs/2003MNRAS.344.1000B/abstract) located in the SSPs directory. These SSPs were computed assuming the STELIB stellar atmospheres, isochrones from the \"Padova group 1994\" and an initial mass function from Chabrier (2003). There is a master file called Base.BC03.S that contains important information with respect to the SSPs:\n",
    "\n",
    "150 [N_base] -> Number of SSPs\n",
    "\n",
    "\\#1 [name of spectrum]        \n",
    "\\#2 [age in years]          \n",
    "\\#3 [metallicity in Z (mass fractions)]         \n",
    "\\#4 [code name]        \n",
    "\\#5 [Mass in stars]     \n",
    "\n",
    "<strong>a)</strong> Compute the magnitudes in the Vega system (don't worry too much about the calibration constant, see below) for the U,B,V filters as a function of time for an instantaneous burst model. The instantaneous burst model for a simple stellar population (SSP) is given by $F^{SSP} (t^{\\prime},Z(t-t^{\\prime}),\\lambda)$, which is a spectrum of age $t^{\\prime}$ and metallicity $Z$ as a function of the wavelength $\\lambda$. The SSP spectrum comes in units of $[L_\\odot Å^{-1} M^{-1}_\\odot]$. The spectra of SSPs can be found in the directory SSPs under the generic name bc2003*.spec. See the Base.BC03.S file for a description of each spectra. Now, using the following equation:\n",
    "\n",
    "<br>\n",
    "$$L(\\lambda,Z,t) = \\int_0^{t} \\int_{m_{low}}^{m_{up}} \\psi(t-t^{\\prime})I\\left(t^{\\prime},Z(t-t^{\\prime}),m,\\lambda\\right) \\phi(m) dm dt^{\\prime}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "$$L(\\lambda,Z,t) = \\int_0^{t} F^{SSP} (t^{\\prime},Z(t-t^{\\prime}),\\lambda)\\psi(t-t^{\\prime}) dt^{\\prime}$$\n",
    "\n",
    "<br> compute the time evolution for the magnitude in these filters assuming a constant star formation rate ($\\psi(t-t^{\\prime}) = C$  $[M_\\odot / \\textrm{year}]$) and a constant enrichment law with solar metallicity, i.e.  $Z(t-t^{\\prime}) = Z_\\odot$. See hint below on how to solve numerically this equation.\n",
    "\n",
    "<strong>b)</strong> Now, compute the time evolution of the magnitudes for the SDSS filters u,g,r as a function of time for the instantaneous and continuous model. These will be used in a later exercise.\n",
    "\n",
    "<strong>c)</strong> UBVRI photometry of galaxies from the Hubble Deep Field South (HDFS) have been observed and described in  Volonteri et al. (2000) - https://ui.adsabs.harvard.edu/abs/2000A%26AS..145..111V/abstract. Plot the colors U-B and B-V for the observed galaxies (you will need to \"clean\" the data, i.e U-B and B-V in the range from [-3,3] and [-2,2] because there are unreliable values ~99). Compare the colors of these galaxies with the obtained colors from the instantaneous burst and continuous models in letter <strong>a)</strong>. Do you think some galaxies can be explained by these models? What could be the reason(s) that some galaxies do not match the colors from the models?\n",
    "\n",
    "Hint:\n",
    "\n",
    "I) The equation above can be simplified with the assumptions:\n",
    "<br><br>$$L(\\lambda,Z,t) = \\int_0^{t} F^{SSP}\\left(t^{\\prime},Z(t-t^{\\prime}),\\lambda\\right)\\psi(t-t^{\\prime})  dt^{\\prime} = \\int_0^{t} F^{SSP}\\left(t^{\\prime},Z_\\odot,\\lambda\\right) C  dt^{\\prime} = C \\int_0^{t} F^{SSP}\\left(t^{\\prime},Z_\\odot,\\lambda\\right) dt^{\\prime}$$\n",
    "<br>\n",
    "\n",
    "$$L(\\lambda,Z,t) \\sim C \\sum_j F^{SSP} \\left(t_j,Z_\\odot,\\lambda\\right) \\Delta t_j\\textrm{, if }t_j \\leq t$$\n",
    "\n",
    "<br>\n",
    "if $\\Delta t_j = \\Delta t = $ constant, then we have the spectrum normalized by the total stellar mass $M_\\star$ ($C =\\frac{M_\\star}{t}$):\n",
    "\n",
    "$$\n",
    "l(\\lambda,Z,t) = \\frac{L(\\lambda,Z,t)}{M_\\star} \\sim \\frac{\\Delta t}{t} \\times \\left[\\sum_j F^{SSP} \\left(t_j,Z_\\odot,\\lambda\\right)\\right],\\textrm{ if }t_j \\leq t\n",
    "$$\n",
    "\n",
    "For each time computed you will need to convolve the spectrum with a given transmission curve from a filter. The transmission curves are in the Filters directory.\n",
    "\n",
    "This linear integration may take too long depending on the $\\Delta t$ chosen. If $\\Delta t$ is too low then the sum of SSPs may take longer to be computed. If $\\Delta t$ is large then the integration may not be accurate. A value of $\\Delta t \\sim 10^6$ years is a safe value, but computationally expensive. One way to circunvent the problem is to compute it in logarithmic steps:\n",
    "\n",
    "$$\\Delta \\log t_j = \\frac{\\Delta t_j}{t_j} \\log e$$\n",
    "\n",
    "Therefore, one may write the equation above as:\n",
    "\n",
    "$$\n",
    "l(\\lambda,Z,t) = \\frac{L(\\lambda,Z,t)}{M_\\star} \\sim \\frac{\\ln(10)}{t} \\times \\left[\\sum_j F^{SSP} \\left(t_j,Z_\\odot,\\lambda\\right) t_j \\Delta \\log t_j\\right],\\textrm{ if }t_j \\leq t\n",
    "$$\n",
    "\n",
    "So, if we take equal steps in the logarithmic space, i.e. $\\Delta \\log t_j = \\Delta \\log t \\sim 0.05$ dex, then:\n",
    "\n",
    "$$\n",
    "l(\\lambda,Z,t) = \\frac{L(\\lambda,Z,t)}{M_\\star} \\sim \\frac{\\ln(10) \\Delta \\log t}{t} \\times \\left[\\sum_j F^{SSP} \\left(t_j,Z_\\odot,\\lambda\\right) t_j \\right],\\textrm{ if }t_j \\leq t\n",
    "$$\n",
    "\n",
    "This formula has a clear advantage over the linear one since we can sum the SSPs  between $\\log t_j = 6$ to $\\log t_j \\sim 9.25$ with a much lower number of elements, which makes it computationally less expensive. In Python, something like np.linspace(6, 9.25, 250) could generate the list needed, for example.\n",
    "\n",
    "II) For the Vega system (Bohlin and Gilland 2004), one can assume that the magnitudes are expressed as:\n",
    "\n",
    "$$\n",
    "m = -2.5 \\log F_{\\textrm{filter}} + C\n",
    "$$\n",
    "\n",
    "where $F_{\\textrm{filter}}$ is the total flux convolved with transmission curve of a given filter and the calibration constant is related to the Vega standard star:\n",
    "\n",
    "$$C = +2.5 \\log F_{\\textrm{filter}}^{Vega} + 0.026 $$\n",
    "\n",
    "where, $F_{\\textrm{filter}}^{Vega}$ is the total flux of Vega convolved with a transmission curve.\n",
    "\n",
    "III) The transmission curves for the filters are located in the directory Filters. The Filters are:\n",
    "\n",
    "[UBV]\n",
    "- MathewsB.txt: B filter\n",
    "- Buse_U.txt: U filter\n",
    "- Buse_V.txt: V filter\n",
    "\n",
    "[SDSS]\n",
    "- SDSS_u.txt: u filter\n",
    "- SDSS_g.txt: g filter\n",
    "- SDSS_r.txt: r filter\n",
    "\n",
    "IV) NOTE: Have you ever used luptitudes? This is the SDSS system. They are expressed as inverse hyperbolic sine (or \"asinh\") magnitudes, described in detail by Lupton, Gunn & Szalay (1999). Here, assume that the magnitudes are given in the Vega system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - CALIFA galaxies as seen from SDSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>3)</strong> We are going to use the galaxies from the CALIFA survey, you can check the 3rd data release here \n",
    "\n",
    "https://califaserv.caha.es/CALIFA_WEB/public_html/?q=content/califa-3rd-data-release \n",
    "\n",
    "and see the poststamps for the photos here \n",
    "\n",
    "https://califaserv.caha.es/CALIFA_WEB/public_html/?q=content/sdss-poststamp-images-dr3-objects&explorer=1. \n",
    "\n",
    "Basically all hubbles types are spanned in this sample, with exception of dwarf galaxies in the low mass regime. See the CALIFA Presentation Article (Sánchez et al. 2012) describing the sample and how was selected. The targets for this survey have been selected from the photometric catalog of the Sloan Digital Sky Survey (SDSS) as a sample limited in apparent isophotal diameter. The PMAS/PPAK integral field spectrophotometer, mounted on the Calar Alto 3.5 m telescope, has been used to observe these galaxies, guaranteeing that the full field-of-view (FoV) was covered.\n",
    "\n",
    "<html>\n",
    "<img src=\"https://raw.githubusercontent.com/neutrinomuon/AST4001/master/CALIFA/CalifaHeader.jpg\" alt=\\\"Snow\\\" width=\\\"65%\\\">\n",
    "</html>     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 different tables in the directory CALIFA describing the mother sample composed of \n",
    "\n",
    "- CALIFA_MotherSample.txt: Main galaxy sample with redshift information\n",
    "- CALIFA_MotherSample_Magnitudes.txt : Magnitudes in the SDSS u,g,r and the band foreground extinctions; r-band Petrosian half-light radius\n",
    "- CALIFA_MotherSample_Mass.txt: Total stellar mass computed with Photometry\n",
    "- CALIFA_MotherSample_Morphology_ReadMe.txt: ReadMe file for the morphological classification\n",
    "- CALIFA_MotherSample_Morphology.txt: Morphological classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>a)</strong> Create from the tables above a master table in FITS format called CALIFA_MotherSample.fits using astropy.io.fits (https://docs.astropy.org/en/stable/io/fits/) containing in the columns:\n",
    "\n",
    "\\#1  CALIFA_ID  \n",
    "\\#2  name  \n",
    "\\#3  RA    \n",
    "\\#4  DEC    \n",
    "\\#5  redshift     \n",
    "\\#6  redshift_CALIFA      \n",
    "\\#7  u     \n",
    "\\#8  u_error     \n",
    "\\#9  u_ext    \n",
    "\\#10 g     \n",
    "\\#11 g_error    \n",
    "\\#12 g_ext     \n",
    "\\#13 r       \n",
    "\\#14 r_error     \n",
    "\\#15 r_ext      \n",
    "\\#17 hubble_type   \n",
    "\\#18 bar   \n",
    "\\#19 merger   \n",
    "\\#20 mstar        \n",
    "\\#21 R_50\n",
    "\n",
    "<strong>b)</strong> Add a new column to the fits table CALIFA_MotherSample.fits with the physical size (in kpc) corresponding to 3 arcsec (size of the fiber) on the sky at the redshift of each galaxy, to understand what is the region sampled by the SDSS spectrum for each galaxy.\n",
    "\n",
    "Hint:\n",
    "For this calculation, you may wish to compute the angular diameter distance in Pyhton using the astropy.cosmology (FlatLambdaCDM) and the function kpc_proper_per_arcmin, which will give the angular separation in arcsec corresponding to a proper kpc at redshift z; you can adopt the following cosmological parameters throughout: $H0 = 70$ km/s/Mpc, $\\Omega_M = 0.3$, $\\Omega_\\Lambda = 0.7$ for a flat universe. \n",
    "\n",
    "<strong>c)</strong> The Petrosian half-light radius in r band $R_{50}$, in arcsec, gives an idea of the size of the galaxy. Roughly, $R_{50}$ is the radius which contains half of the ligth of a galaxy in a given band. Compute the physical size in kpc of $R_{50}$. Plot the mass-size relation, i.e. mstar versus $R_{50}$. Do you see any correlation? Why? Do you think it is justified to use integral field spectroscopy?\n",
    "\n",
    "<!-- This is commented out. <strike><strong>d)</strong> If you plot u-g versus g-r observed colors obtained from SDSS (galaxies from the CALIFA survey) (with respective error bars), would you be able to describe a fraction of the galaxies with the color evolution derived in problem <strong>2 -b)</strong> for the instantaneous of continuous models? Elaborate your final answer.</strike>\n",
    "Hint : Here the magnitudes of SDSS are not corrected for extinction. Correct it using the table created on <strong>a)</strong> and with the following formula: \n",
    "<br>$$m_{\\lambda}= -2.5 \\log(F_{\\lambda}) + A_{\\lambda} + C$$\n",
    "<br>$$ m_{\\lambda} = m_{\\lambda,corr} + A_{\\lambda}$$\n",
    "<br>$$m_{\\lambda,corr} = m - A_{\\lambda}$$</p> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 2\n",
    "\n",
    "##  Part 3 - FADO population synthesis code applied to SDSS-spectra from  the CALIFA survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>4)</strong> Assume that you have downloaded the FADO population synthesis code from the repository at www.github.com/neutrinomuon/AST4001. First clone the repository to your machine. If you want you may check on how to run FADO at  page \n",
    "\n",
    "https://github.com/neutrinomuon/AST4001/blob/master/FADO_Execute_ListOfGalaxies-GITHUB.ipynb\n",
    "\n",
    "Assume you have ran FADO in the list mode for all 644 galaxies with SDSS spectra used in the CALIFA survey. The reduced spectra of these galaxies are located at the directory CALIFA/spectra/ (corrected for Galactic extinction and redshift). They are in ascii format and have the following nomenclature spec-fiberID-MJD-plateID.fits.ascii. You have produced the following output files *.fits plus *.eps at the directory CALIFA/Output/ and the FADO master tables:\n",
    "\n",
    "- SampleEmissionEL_lista_SDSS_CALIFA.txt.table and \n",
    "- SampleStatistics_lista_SDSS_CALIFA.txt.table \n",
    "\n",
    "are at CALIFA/Tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>a)</strong> From the tables obtained after processing these galaxies with FADO, plot the mean stellar age light-weighted as a function of the mean stellar metallicity light-weighted. Use the size of the dots to show the total stellar mass in the fiber. Is there a correlation? Why?\n",
    "\n",
    "<strong>b)</strong> Compute the recent star formation rate from the luminosity of the H$\\alpha$ emission-line in the fiber, expressing your result in $[M_\\odot/\\textrm{year}]$, using the empirical formula derived by Kennicutt (1998, ApJ, 498, 541; note that this formula assumes a Salpeter IMF).\n",
    "\n",
    "Hint:\n",
    "\n",
    "Recall that you need to correct the observed H$\\alpha$ flux from the internal extinction present in each galaxy. To obtain the mean extinction at the wavelength of H$\\alpha$ ($A_{\\textrm{H}\\alpha}$), from the data (namely, from the parameter <b>Gnebular</b>, that stands for AV and was derived by FADO for each galaxy), use the Cardelli, Clayton & Mathis (1989, ApJ, 345, 245) - https://ui.adsabs.harvard.edu/abs/1989ApJ...345..245C/abstract - mean extinction law and their equations (1), (3a) and (3b). You may also wish to use the python module extinction - https://extinction.readthedocs.io/en/latest/ to correct the flux luminosities.\n",
    "\n",
    "<strong>c)</strong> The BPT diagrams (named after \"Baldwin, Phillips & Telervich\") are a set of nebular emission line ratio diagrams used to distinguish the ionization source of gas. The most famous and used version consists of $[NII]_{6584}$/$H\\alpha$ versus $[OIII]_{5007}$/$H\\beta$ (<b>the BPT-NII diagram</b>; Fig. 5 of Baldwin et al. 1981). These diagrams were studied in distinct works to separate and classify different types of galaxies. For instance, dividing lines have been developed and adapted as a function of the ionization models and/or observations available (e.g., Veilleux & Osterbrock 1987; Osterbrock 1989; Kewley et al 2001; Kauffmann et al. 2003; Kewley et al. 2006; Stasińska et al. 2006; Kewley et al. 2013a,b).  \n",
    "\n",
    "Below are listed the demarcations summarized by Kewley et al. 2006 for each diagram:\n",
    "\n",
    "        1- log([OIII]/Hβ) = 0.61 / (log([NII]/Hα) - 0.05) + 1.30 \n",
    "        (Kauffmann et al. 2003 line)\n",
    "        \n",
    "        2- log([OIII]/Hβ) = 0.61 / (log([NII]/Hα) - 0.47) + 1.19 \n",
    "        (Kewley et al. 2001 line)\n",
    "        \n",
    "        3- log([OIII]/Hβ) = 1.01 * (log([NII]/Hα) + 0.48 \n",
    "        (Cid Fernandes et al. 2010 line)\n",
    "\n",
    "Where, relation 1 is used to separate galaxies that are star-forming for values lower than this demarcation line, and relation 2 is used to separate galaxies that are either Seyfert and/or LINERs, for values higher than this demarcation line. Galaxies falling in between lines 1 and 2 are called Composites. Galaxies in the upper-right branch can be further subdivided into LINERs and Seyfert using the demarcation line 3, valid only above relation 2.\n",
    "\n",
    "Plot for these galaxies the BPT-NII diagram and draw the demarcation lines. Do you think that, for any galaxy in this sample, you may be incurring in an error in <strong>c)</strong> by using the H$\\alpha$ flux to compute the SFR? Why? If you answered affirmatively, which galaxy(ies) may be affected by such an error?\n",
    "\n",
    "<strong>d)</strong> We should, in principle, use the total SFR from and total stellar mass, but we will make use only of the fiber quantities. Plot the SFR versus total stellar mass in the fiber using blue color for the star-forming galaxies and the others in red. Can you explain the result? Why there seems to have two different sequences? Find the best linear fit to the star-forming galaxies.\n",
    "\n",
    "Hint:\n",
    "\n",
    "I) You can use the python module ReadFADOTables_AST4001.py located inside the directory Tables to read the quantitites needed to this exercise.\n",
    "\n",
    "II) For the BPT-NII diagram, you do not need to correct the emission-lines for extinction. Think and explain why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>5)</strong> Check all your results and the available data in tables (photometric and spectroscopic catalogs). Provide any additional test you may think of, briefly explaining why you did it, what you aimed at testing, what you expected, what you actually got and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
